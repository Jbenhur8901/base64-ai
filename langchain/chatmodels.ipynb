{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a416ec85",
   "metadata": {},
   "source": [
    "## 🧠 Qu’est-ce qu’un modèle de chat ?\n",
    "\n",
    "Les **modèles de chat** sont des interfaces qui permettent d'interagir avec des **grands modèles de langage (LLM)** via une série de messages, simulant ainsi une conversation humaine. LangChain fournit une interface cohérente pour travailler avec ces modèles, indépendamment du fournisseur, tout en offrant des fonctionnalités supplémentaires pour le suivi, le débogage et l'optimisation des performances des applications utilisant des LLM\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Fonctionnalités principales\n",
    "\n",
    "- 🔧 **Appel d’outils (Tool Calling)** : permet aux modèles d'exécuter des fonctions personnalisées (APIs, outils externes, agents...).\n",
    "- 🧾 **Sortie structurée** : génère des réponses JSON selon un schéma défini.\n",
    "- 🖼️ **Multimodalité** : certains modèles traitent du texte, mais aussi des images ou du son.\n",
    "- 🌊 **Streaming** : renvoie les réponses progressivement, token par token.\n",
    "- 🧺 **Batching** : traitement de plusieurs requêtes en parallèle pour optimiser les appels.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Paramètres standards des modèles\n",
    "\n",
    "| Paramètre        | Description                                                                 |\n",
    "|------------------|-----------------------------------------------------------------------------|\n",
    "| `model`          | Nom du modèle à utiliser (ex. `gpt-4`, `claude-3-opus`).                    |\n",
    "| `temperature`    | Contrôle la créativité : `0` (réponse fiable) → `1` (réponse imaginative).   |\n",
    "| `max_tokens`     | Nombre maximum de tokens générés.                                           |\n",
    "| `stop`           | Liste de séquences où la génération doit s’arrêter.                         |\n",
    "| `timeout`        | Délai maximal d’attente de réponse (en secondes).                           |\n",
    "| `max_retries`    | Nombre de tentatives en cas d’échec de l’appel.                             |\n",
    "| `api_key`        | Clé API pour authentification.                                              |\n",
    "| `base_url`       | URL personnalisée du fournisseur si nécessaire.                             |\n",
    "| `rate_limiter`   | Contrôle du débit pour éviter les erreurs de quota.                         |\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Méthodes disponibles\n",
    "\n",
    "- `invoke(messages)`  \n",
    "  Appel standard d’un modèle de chat avec une liste de messages.\n",
    "\n",
    "- `stream(messages)`  \n",
    "  Retourne la réponse en temps réel, idéale pour le live chat.\n",
    "\n",
    "- `with_structured_output(schema)`  \n",
    "  Contraint la sortie à respecter un format structuré (ex : dictionnaire Python).\n",
    "\n",
    "- `bind_tools(tools)`  \n",
    "  Connecte des outils externes à utiliser durant la conversation.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 Fournisseurs compatibles\n",
    "\n",
    "LangChain supporte les principaux fournisseurs :\n",
    "- **OpenAI**\n",
    "- **Anthropic**\n",
    "- **Azure OpenAI**\n",
    "- **Ollama**\n",
    "- **Amazon Bedrock**\n",
    "- **Google Vertex AI**\n",
    "- **Hugging Face**\n",
    "- **Groq**, etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f2c4a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
